{"version":3,"file":"3127.0bd0b2da7c02c81dc7d7.js?v=0bd0b2da7c02c81dc7d7","mappings":"8KAAA,IAAIA,EAEJ,SAASC,EAAWC,GAClB,OAAO,IAAIC,OAAO,OAASD,EAAME,KAAK,KAAO,KAAM,IACrD,CACA,IAAIC,EAAMJ,EAAW,CAAC,MAAO,OAAQ,cAAe,WAAY,QAAS,WAAY,QAAS,QACxE,MAAO,MAAO,QAAS,QAAS,MAAO,MAAO,MAAO,MAAO,SAC5D,eAAgB,OAAQ,MAAO,OAAQ,QAAS,QAAS,SAAU,SAAU,SAC7E,UAAW,QAAS,QAAS,iBAAkB,WAAY,YAAa,UACxE,YAAa,WAAY,OAAQ,QAAS,MAAO,QAAS,UAAW,UACrE,WAAY,KAAM,MAAO,OAAQ,UAAW,MAAO,OAAQ,SAAU,SACrE,SAAU,WAAY,KAAM,UAAW,QAAS,YAAa,QAAS,SACtE,UAAW,YAAa,IAAK,SACnD,IAAIK,EAAWL,EAAW,CAAC,OAAQ,SAAU,SAAU,WAAY,UAAW,YAAa,WAChE,MAAO,OAAQ,QAAS,QAAS,QAAS,QAAS,SAAU,SAAU,WACvE,QAAS,KAAM,MAAO,OAAQ,KAAM,SAAU,QAAS,SAAU,QACjE,QAAS,KAAM,MAAO,UAAW,SAAU,QAAS,SAAU,SAAU,QACxE,OAAQ,QAAS,OACjB,OAAQ,OAAQ,KAAM,OAAQ,MAAO,SAAU,OAAQ,QAAS,OAAQ,SACnG,IAAIM,EAAgB,qBAEpB,SAASC,EAAUC,EAAQC,GACzB,IAAIC,EAAKF,EAAOG,OAChBZ,EAAU,KACV,GAAIW,GAAM,KAAOA,GAAM,IAAK,CAC1B,GAAGA,GAAM,KAAOF,EAAOI,MAAM,KAAM,OAAO,CACxC,MAAO,UACT,CACAJ,EAAOI,MAAM,kUACb,MAAO,oBACT,MACK,GAAIF,GAAM,MAAQF,EAAOI,MAAM,eAAgB,OAAQ,CAC1DJ,EAAOI,MAAM,oBACb,MAAO,MACT,MACK,GAAIF,GAAM,KAAQA,GAAM,IAAK,CAChCD,EAAMI,SAAWC,EAAaJ,GAC9B,OAAOD,EAAMI,SAASL,EAAQC,EAChC,MACK,GAAI,mBAAmBM,KAAKL,GAAK,CACpCX,EAAUW,EACV,MAAO,SACT,MACK,GAAIA,GAAM,IAAK,CAClBF,EAAOQ,YACP,MAAO,SACT,MACK,GAAIV,EAAcS,KAAKL,GAAK,CAC/B,MAAO,UACT,MACK,GAAIA,GAAM,IAAK,CAClBO,EAAWT,GACX,MAAO,MACT,MACK,GAAIE,GAAM,IAAK,CAClBF,EAAOU,SAAS,cAChB,MAAO,MACT,KACK,CACHV,EAAOU,SAAS,WAChB,GAAIV,EAAOW,IAAI,KAAM,CACnBF,EAAWT,GACX,MAAO,MACT,CACA,IAAIY,EAAOZ,EAAOa,UAClB,GAAIjB,EAAIW,KAAKK,GACX,MAAO,eACJ,GAAIf,EAASU,KAAKK,GACrB,MAAO,eAEP,MAAO,UACX,CACF,CAEA,SAASH,EAAWT,GAClBA,EAAOI,MAAM,0EACf,CAEA,SAASE,EAAaQ,GACpB,OAAO,SAASd,EAAQC,GACtB,IAAIc,EAAU,MAAOb,EACrB,OAAQA,EAAKF,EAAOG,SAAW,KAAM,CACnC,GAAID,GAAMY,IAAUC,EAAS,CAC3Bd,EAAMI,SAAWN,EACjB,KACF,CACAgB,GAAWA,GAAWb,GAAM,IAC9B,CACA,MAAO,QACT,CACF,CAEA,SAASc,EAAYf,EAAOgB,EAAMC,GAChCjB,EAAMkB,QAAU,CAACC,KAAMnB,EAAMkB,QAASE,OAAQpB,EAAMoB,OAAQH,IAAKA,EAAKD,KAAMA,EAC9E,CACA,SAASK,EAAWrB,GAClBA,EAAMoB,OAASpB,EAAMkB,QAAQE,OAC7BpB,EAAMkB,QAAUlB,EAAMkB,QAAQC,IAChC,CAEO,MAAMG,EAAS,CACpBC,KAAM,SAENC,WAAY,WACV,MAAO,CAACpB,SAAUN,EACVoB,QAAS,KACTE,OAAQ,EACRH,IAAK,EACf,EAEAQ,MAAO,SAAS1B,EAAQC,GACtB,GAAID,EAAO2B,MAAO,CAChB,GAAI1B,EAAMkB,SAAWlB,EAAMkB,QAAQS,OAAS,KAAM3B,EAAMkB,QAAQS,MAAQ,MACxE3B,EAAMoB,OAASrB,EAAO6B,aACxB,CACA,GAAI7B,EAAO8B,WAAY,OAAO,KAC9B,IAAIC,EAAQ9B,EAAMI,SAASL,EAAQC,GAEnC,GAAI8B,GAAS,WAAa9B,EAAMkB,SAAWlB,EAAMkB,QAAQS,OAAS,MAAQ3B,EAAMkB,QAAQF,MAAQ,UAAW,CACzGhB,EAAMkB,QAAQS,MAAQ,IACxB,CAEA,GAAIrC,GAAW,IAAKyB,EAAYf,EAAO,IAAKD,EAAOgC,eAC9C,GAAIzC,GAAW,IAAKyB,EAAYf,EAAO,IAAKD,EAAOgC,eACnD,GAAIzC,GAAW,IAAKyB,EAAYf,EAAO,IAAKD,EAAOgC,eACnD,GAAI,WAAWzB,KAAKhB,GAAU,CACjC,MAAOU,EAAMkB,SAAWlB,EAAMkB,QAAQF,MAAQ,UAAWK,EAAWrB,GACpE,GAAIA,EAAMkB,SAAW5B,GAAWU,EAAMkB,QAAQF,KAAM,CAClDK,EAAWrB,GACX,GAAIV,GAAW,KAAOU,EAAMkB,SAAWlB,EAAMkB,QAAQF,MAAQ,UAC3DK,EAAWrB,EACf,CACF,MACK,GAAIV,GAAW,KAAOU,EAAMkB,SAAWlB,EAAMkB,QAAQF,MAAQ,UAAWK,EAAWrB,QACnF,GAAI,uBAAuBM,KAAKwB,IAAU9B,EAAMkB,QAAS,CAC5D,GAAI,SAASZ,KAAKN,EAAMkB,QAAQF,MAC9BD,EAAYf,EAAO,UAAWD,EAAOgC,eAClC,GAAI/B,EAAMkB,QAAQF,MAAQ,YAAchB,EAAMkB,QAAQS,MAAO,CAChE3B,EAAMkB,QAAQS,MAAQ,KACtB3B,EAAMkB,QAAQD,IAAMlB,EAAOgC,QAC7B,CACF,CAEA,OAAOD,CACT,EAEAV,OAAQ,SAASpB,EAAOgC,EAAWC,GACjC,IAAIC,EAAYF,GAAaA,EAAUG,OAAO,GAC9C,IAAIjB,EAAUlB,EAAMkB,QACpB,GAAI,SAASZ,KAAK4B,GAChB,MAAOhB,GAAWA,EAAQF,MAAQ,UAAWE,EAAUA,EAAQC,KAEjE,IAAIiB,EAAUlB,GAAWgB,GAAahB,EAAQF,KAC9C,IAAKE,EACH,OAAO,OACJ,GAAIA,EAAQF,MAAQ,UACvB,OAAOE,EAAQD,SACZ,GAAIC,EAAQS,MACf,OAAOT,EAAQD,KAAOmB,EAAU,EAAI,QAEpC,OAAOlB,EAAQE,QAAUgB,EAAU,EAAIH,EAAGI,KAC9C,EAEAC,aAAc,CACZC,cAAe,CAACC,KAAM,M","sources":["webpack://@jupyterlab/application-top/./node_modules/@codemirror/legacy-modes/mode/sparql.js"],"sourcesContent":["var curPunc;\n\nfunction wordRegexp(words) {\n  return new RegExp(\"^(?:\" + words.join(\"|\") + \")$\", \"i\");\n}\nvar ops = wordRegexp([\"str\", \"lang\", \"langmatches\", \"datatype\", \"bound\", \"sameterm\", \"isiri\", \"isuri\",\n                      \"iri\", \"uri\", \"bnode\", \"count\", \"sum\", \"min\", \"max\", \"avg\", \"sample\",\n                      \"group_concat\", \"rand\", \"abs\", \"ceil\", \"floor\", \"round\", \"concat\", \"substr\", \"strlen\",\n                      \"replace\", \"ucase\", \"lcase\", \"encode_for_uri\", \"contains\", \"strstarts\", \"strends\",\n                      \"strbefore\", \"strafter\", \"year\", \"month\", \"day\", \"hours\", \"minutes\", \"seconds\",\n                      \"timezone\", \"tz\", \"now\", \"uuid\", \"struuid\", \"md5\", \"sha1\", \"sha256\", \"sha384\",\n                      \"sha512\", \"coalesce\", \"if\", \"strlang\", \"strdt\", \"isnumeric\", \"regex\", \"exists\",\n                      \"isblank\", \"isliteral\", \"a\", \"bind\"]);\nvar keywords = wordRegexp([\"base\", \"prefix\", \"select\", \"distinct\", \"reduced\", \"construct\", \"describe\",\n                           \"ask\", \"from\", \"named\", \"where\", \"order\", \"limit\", \"offset\", \"filter\", \"optional\",\n                           \"graph\", \"by\", \"asc\", \"desc\", \"as\", \"having\", \"undef\", \"values\", \"group\",\n                           \"minus\", \"in\", \"not\", \"service\", \"silent\", \"using\", \"insert\", \"delete\", \"union\",\n                           \"true\", \"false\", \"with\",\n                           \"data\", \"copy\", \"to\", \"move\", \"add\", \"create\", \"drop\", \"clear\", \"load\", \"into\"]);\nvar operatorChars = /[*+\\-<>=&|\\^\\/!\\?]/;\n\nfunction tokenBase(stream, state) {\n  var ch = stream.next();\n  curPunc = null;\n  if (ch == \"$\" || ch == \"?\") {\n    if(ch == \"?\" && stream.match(/\\s/, false)){\n      return \"operator\";\n    }\n    stream.match(/^[A-Za-z0-9_\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][A-Za-z0-9_\\u00B7\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u203F-\\u2040\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD]*/);\n    return \"variableName.local\";\n  }\n  else if (ch == \"<\" && !stream.match(/^[\\s\\u00a0=]/, false)) {\n    stream.match(/^[^\\s\\u00a0>]*>?/);\n    return \"atom\";\n  }\n  else if (ch == \"\\\"\" || ch == \"'\") {\n    state.tokenize = tokenLiteral(ch);\n    return state.tokenize(stream, state);\n  }\n  else if (/[{}\\(\\),\\.;\\[\\]]/.test(ch)) {\n    curPunc = ch;\n    return \"bracket\";\n  }\n  else if (ch == \"#\") {\n    stream.skipToEnd();\n    return \"comment\";\n  }\n  else if (operatorChars.test(ch)) {\n    return \"operator\";\n  }\n  else if (ch == \":\") {\n    eatPnLocal(stream);\n    return \"atom\";\n  }\n  else if (ch == \"@\") {\n    stream.eatWhile(/[a-z\\d\\-]/i);\n    return \"meta\";\n  }\n  else {\n    stream.eatWhile(/[_\\w\\d]/);\n    if (stream.eat(\":\")) {\n      eatPnLocal(stream);\n      return \"atom\";\n    }\n    var word = stream.current();\n    if (ops.test(word))\n      return \"builtin\";\n    else if (keywords.test(word))\n      return \"keyword\";\n    else\n      return \"variable\";\n  }\n}\n\nfunction eatPnLocal(stream) {\n  stream.match(/(\\.(?=[\\w_\\-\\\\%])|[:\\w_-]|\\\\[-\\\\_~.!$&'()*+,;=/?#@%]|%[a-f\\d][a-f\\d])+/i);\n}\n\nfunction tokenLiteral(quote) {\n  return function(stream, state) {\n    var escaped = false, ch;\n    while ((ch = stream.next()) != null) {\n      if (ch == quote && !escaped) {\n        state.tokenize = tokenBase;\n        break;\n      }\n      escaped = !escaped && ch == \"\\\\\";\n    }\n    return \"string\";\n  };\n}\n\nfunction pushContext(state, type, col) {\n  state.context = {prev: state.context, indent: state.indent, col: col, type: type};\n}\nfunction popContext(state) {\n  state.indent = state.context.indent;\n  state.context = state.context.prev;\n}\n\nexport const sparql = {\n  name: \"sparql\",\n\n  startState: function() {\n    return {tokenize: tokenBase,\n            context: null,\n            indent: 0,\n            col: 0};\n  },\n\n  token: function(stream, state) {\n    if (stream.sol()) {\n      if (state.context && state.context.align == null) state.context.align = false;\n      state.indent = stream.indentation();\n    }\n    if (stream.eatSpace()) return null;\n    var style = state.tokenize(stream, state);\n\n    if (style != \"comment\" && state.context && state.context.align == null && state.context.type != \"pattern\") {\n      state.context.align = true;\n    }\n\n    if (curPunc == \"(\") pushContext(state, \")\", stream.column());\n    else if (curPunc == \"[\") pushContext(state, \"]\", stream.column());\n    else if (curPunc == \"{\") pushContext(state, \"}\", stream.column());\n    else if (/[\\]\\}\\)]/.test(curPunc)) {\n      while (state.context && state.context.type == \"pattern\") popContext(state);\n      if (state.context && curPunc == state.context.type) {\n        popContext(state);\n        if (curPunc == \"}\" && state.context && state.context.type == \"pattern\")\n          popContext(state);\n      }\n    }\n    else if (curPunc == \".\" && state.context && state.context.type == \"pattern\") popContext(state);\n    else if (/atom|string|variable/.test(style) && state.context) {\n      if (/[\\}\\]]/.test(state.context.type))\n        pushContext(state, \"pattern\", stream.column());\n      else if (state.context.type == \"pattern\" && !state.context.align) {\n        state.context.align = true;\n        state.context.col = stream.column();\n      }\n    }\n\n    return style;\n  },\n\n  indent: function(state, textAfter, cx) {\n    var firstChar = textAfter && textAfter.charAt(0);\n    var context = state.context;\n    if (/[\\]\\}]/.test(firstChar))\n      while (context && context.type == \"pattern\") context = context.prev;\n\n    var closing = context && firstChar == context.type;\n    if (!context)\n      return 0;\n    else if (context.type == \"pattern\")\n      return context.col;\n    else if (context.align)\n      return context.col + (closing ? 0 : 1);\n    else\n      return context.indent + (closing ? 0 : cx.unit);\n  },\n\n  languageData: {\n    commentTokens: {line: \"#\"}\n  }\n};\n\n"],"names":["curPunc","wordRegexp","words","RegExp","join","ops","keywords","operatorChars","tokenBase","stream","state","ch","next","match","tokenize","tokenLiteral","test","skipToEnd","eatPnLocal","eatWhile","eat","word","current","quote","escaped","pushContext","type","col","context","prev","indent","popContext","sparql","name","startState","token","sol","align","indentation","eatSpace","style","column","textAfter","cx","firstChar","charAt","closing","unit","languageData","commentTokens","line"],"sourceRoot":""}